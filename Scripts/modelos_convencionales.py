# -*- coding: utf-8 -*-
"""Modelos_Convencionales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RhkCbmL0oXvpttoWkas0_8TLXtPqR21v

# **Importación de los datos**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np


# URL del archivo CSV en GitHub
train =  pd.read_csv('https://media.githubusercontent.com/media/Jacks3262/repo_HACKATHON_2024/main/Datasets/fraude.csv')

"""La seleccion de los valores de test se utilizaron en base a los valores correctos obtenidos del repositorio de Github obtenidos a través de Kaggle: https://www.kaggle.com/datasets/wesleyhowe/titanic-labelled-test-set. Esto fue consultado con el profesor Ivan, debido a que se obtiene un 100% de accuracy al subirlo en Kaggle"""

df = train

"""# Entrenamiento del modelo"""

from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

from sklearn.model_selection import train_test_split

# Suponiendo que tienes un DataFrame llamado 'df' y quieres predecir una variable llamada 'target'
X = df[['edad_cliente', 'monto_transaccion', 'mañana', 'tarde', 'noche', 'madrugada', 'presencial', 'nacional', 'internacional', 'sexo',
        'fechas_decembrinas', 'categoria_peligrosa']] # Características (X)
y = df['Fraude']  # Variable de respuesta (y)

# Dividir el DataFrame en un 80% para entrenamiento y 20% para prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Ajustar el escalador solo con los datos de entrenamiento y transformar
X_train = scaler.fit_transform(X_train)

# Transformar el conjunto de prueba usando el mismo escalador
X_test = scaler.transform(X_test)

# Mostrar el tamaño de los conjuntos
print(f"Train set size: {X_train.shape}")
print(f"Test set size: {X_test.shape}")

len(X_test)

"""Calcula e imprime la exactitud, recall, f1-score, precisión y el área bajo la curva ROC (ROC AUC) para los datos de prueba.

"""

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score

def print_scores(fitted_model):
    res = {
        "Accuracy on train:": accuracy_score(fitted_model.predict(X_train), y_train),
        "Recall on train:": recall_score(fitted_model.predict(X_train), y_train),
        "Precision on train:": precision_score(fitted_model.predict(X_train), y_train),
        "F1-Score on train:": f1_score(fitted_model.predict(X_train), y_train),
        "ROC AUC on train:": roc_auc_score(y_train, fitted_model.predict_proba(X_train)[:, 1]),

        "Accuracy on test:": accuracy_score(fitted_model.predict(X_test), y_test),
        "Recall on test:": recall_score(fitted_model.predict(X_test), y_test),
        "Precision on test:": precision_score(fitted_model.predict(X_test), y_test),
        "F1-Score on test:": f1_score(fitted_model.predict(X_test), y_test),
        "ROC AUC on test:": roc_auc_score(y_test, fitted_model.predict_proba(X_test)[:, 1]),
    }

    # Imprimir solo las métricas de prueba (test) con un formato específico
    for k, v in res.items():
        #if 'on test' in k:  # Filtrar para incluir solo las claves que contienen 'on test'
            print(k, round(v, 3))
    print("-" * 30)  # Línea separadora para claridad en la salida

"""# **Resultados**"""

# Regresión Logística
print('Regresión Logística')

# Modelo 1: Regresión Logística con C=0.01, solver='liblinear', max_iter=1000
model_1 = LogisticRegression(C=0.01, solver='liblinear', max_iter=1000)
model_1.fit(X_train, y_train)
print_scores(model_1)


# Modelo 2: Regresión Logística con C=1, solver='sag', max_iter=2000
#model_2 = LogisticRegression(C=1, solver='sag', max_iter=2000)
#model_2.fit(X_train, y_train)
#print_scores(model_2)

# Modelo 3: Regresión Logística con C=10, solver='newton-cg', max_iter=3000
model_3 = LogisticRegression(C=10, solver='newton-cg', max_iter=3000)
model_3.fit(X_train, y_train)
print_scores(model_3)

# Modelo 4: Regresión Logística con C=0.05, solver='saga', max_iter=5000, penalty='l2'
# model_4 = LogisticRegression(C=0.05, solver='saga', max_iter=5000, penalty='l2')
# model_4.fit(X_train, y_train)
# print_scores(model_4)

# Modelo 5: Regresión Logística con C=0.5, solver='lbfgs', max_iter=1000, penalty='l2'
model_5 = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, penalty='l2')
model_5.fit(X_train, y_train)
print_scores(model_5)

print('')
print('Árboles de decisión')

# Árbol de decisión 1: max_depth=30, min_samples_split=2, criterion='gini'
tree_model_1 = DecisionTreeClassifier(max_depth=30, min_samples_split=2, criterion='gini')
tree_model_1.fit(X_train, y_train)
print_scores(tree_model_1)

# Árbol de decisión 2: max_depth=100, min_samples_split=10, criterion='entropy'
tree_model_2 = DecisionTreeClassifier(max_depth=100, min_samples_split=10, criterion='entropy')
tree_model_2.fit(X_train, y_train)
print_scores(tree_model_2)

# Árbol de decisión 3: max_depth=150, min_samples_split=5, criterion='gini'
tree_model_3 = DecisionTreeClassifier(max_depth=150, min_samples_split=5, criterion='gini')
tree_model_3.fit(X_train, y_train)
print_scores(tree_model_3)

print('')
print('Random Forest')

# Random Forest 1: n_estimators=50, max_features='sqrt', max_depth=50
rf_model_1 = RandomForestClassifier(n_estimators=50, max_features='sqrt', max_depth=50)
rf_model_1.fit(X_train, y_train)
print_scores(rf_model_1)

# Random Forest 2: n_estimators=100, max_features='log2', max_depth=100
rf_model_2 = RandomForestClassifier(n_estimators=100, max_features='log2', max_depth=100)
rf_model_2.fit(X_train, y_train)
print_scores(rf_model_2)

# Random Forest 3: n_estimators=200, max_features='sqrt', max_depth=200
rf_model_3 = RandomForestClassifier(n_estimators=200, max_features='sqrt', max_depth=200)
rf_model_3.fit(X_train, y_train)
print_scores(rf_model_3)

# Random Forest 4: n_estimators=150, max_features='sqrt', max_depth=250, min_samples_split=4
rf_model_4 = RandomForestClassifier(n_estimators=150, max_features='sqrt', max_depth=250, min_samples_split=4)
rf_model_4.fit(X_train, y_train)
print_scores(rf_model_4)

# Random Forest 5: n_estimators=300, max_features='log2', max_depth=300, min_samples_leaf=2
rf_model_5 = RandomForestClassifier(n_estimators=300, max_features='log2', max_depth=300, min_samples_leaf=2)
rf_model_5.fit(X_train, y_train)
print_scores(rf_model_5)

"""## **Mejor Modelo Convencional**"""

model_5 = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, penalty='l2')
model_5.fit(X_train, y_train)
# print_scores(model_5)

# Pedir al usuario que ingrese los valores de cada característica
nuevo_registro = {
    'edad_cliente': int(input('Enter the client\'s age: ')),
    'monto_transaccion': float(input('Enter the transaction amount: ')),
    'mañana': int(input('Transaction in the morning? (1 for yes, 0 for no): ')),
    'tarde': int(input('Transaction in the afternoon? (1 for yes, 0 for no): ')),
    'noche': int(input('Transaction at night? (1 for yes, 0 for no): ')),
    'madrugada': int(input('Transaction at dawn? (1 for yes, 0 for no): ')),
    'presencial': int(input('In-person transaction? (1 for yes, 0 for no): ')),
    'nacional': int(input('National transaction? (1 for yes, 0 for no): ')),
    'internacional': int(input('International transaction? (1 for yes, 0 for no): ')),
    'sexo': int(input('Client\'s gender (1 for female, 0 for male): ')),
    'fechas_decembrinas': int(input('Transaction during December holidays? (1 for yes, 0 for no): ')),
    'categoria_peligrosa': int(input('Dangerous category? (1 for yes, 0 for no): '))
}

# Convertir el registro a DataFrame y asegurarse de que siga el orden de las columnas de entrenamiento
X_nuevo = pd.DataFrame([nuevo_registro])

# Escalar los datos si fue parte del preprocesamiento
X_nuevo_scaled = scaler.transform(X_nuevo)

# Realizar la predicción
prediccion = model_5.predict(X_nuevo_scaled)

# Mostrar la predicción
if prediccion[0] == 0:
    print('No Fraud')
else:
    print('Fraud')

print('----------------------------------')

# Pedir al usuario que ingrese los valores de cada característica
nuevo_registro = {
    'edad_cliente': int(input('Enter the client\'s age: ')),
    'monto_transaccion': float(input('Enter the transaction amount: ')),
    'mañana': int(input('Transaction in the morning? (1 for yes, 0 for no): ')),
    'tarde': int(input('Transaction in the afternoon? (1 for yes, 0 for no): ')),
    'noche': int(input('Transaction at night? (1 for yes, 0 for no): ')),
    'madrugada': int(input('Transaction at dawn? (1 for yes, 0 for no): ')),
    'presencial': int(input('In-person transaction? (1 for yes, 0 for no): ')),
    'nacional': int(input('National transaction? (1 for yes, 0 for no): ')),
    'internacional': int(input('International transaction? (1 for yes, 0 for no): ')),
    'sexo': int(input('Client\'s gender (1 for female, 0 for male): ')),
    'fechas_decembrinas': int(input('Transaction during December holidays? (1 for yes, 0 for no): ')),
    'categoria_peligrosa': int(input('Dangerous category? (1 for yes, 0 for no): '))
}

# Convertir el registro a DataFrame y asegurarse de que siga el orden de las columnas de entrenamiento
X_nuevo = pd.DataFrame([nuevo_registro])

# Escalar los datos si fue parte del preprocesamiento
X_nuevo_scaled = scaler.transform(X_nuevo)

# Realizar la predicción
prediccion = model_5.predict(X_nuevo_scaled)

# Mostrar la predicción
if prediccion[0] == 0:
    print('No Fraud')
else:
    print('Fraud')





















"""# GridSearchCV"""

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
import warnings

# Ignorar todos los warnings
warnings.filterwarnings('ignore')

# Definir los modelos y sus respectivos hiperparámetros para la búsqueda
models = {
    'LogisticRegression': {
        'model': LogisticRegression(),
        'params': {
            'solver': ['newton-cg', 'lbfgs', 'liblinear'],
            'C': [0.001, 0.01, 0.1, 1, 10, 100],
            'max_iter': [100, 200, 300, 400, 500],
            'penalty': ['l2', 'l1', 'elasticnet', 'none'],
            'l1_ratio': [0.0, 0.15, 0.5, 0.7, 1.0]  # Solo aplicable con 'elasticnet'
        }
    }
}

# Ejecutar GridSearchCV para cada modelo
best_models = {}
for model_name, config in models.items():
    print(f"Buscando mejores parámetros para {model_name}...")
    # Cambiar el scoring a 'recall' para mejorar el recall en lugar del accuracy
    grid = GridSearchCV(config['model'], config['params'], cv=5, n_jobs=-1, scoring='recall')
    grid.fit(X_train, y_train)
    best_models[model_name] = grid.best_estimator_
    print(f"Mejor recall para {model_name}: {grid.best_score_:.4f}")
    print(f"Mejores parámetros: {grid.best_params_}")
    print("-" * 50)

# Evaluar el mejor modelo de cada tipo en el conjunto de prueba
for model_name, model in best_models.items():
    y_pred = model.predict(X_test)
    recall = recall_score(y_test, y_pred)
    print(f"Recall en prueba para {model_name}: {recall:.4f}")

# Definir los modelos y sus respectivos hiperparámetros para la búsqueda
models_configs = {
    'LogisticRegression': {
        'model': LogisticRegression(),
        'params': {
            'solver': ['newton-cg', 'lbfgs', 'liblinear'],
            'C': [0.001, 0.01, 0.1, 1, 10, 100],
            'max_iter': [100, 200, 300, 400, 500],
            'penalty': ['l2', 'l1', 'elasticnet', 'none'],
            'l1_ratio': [0.0, 0.15, 0.5, 0.7, 1.0]  # Solo aplicable con 'elasticnet'
        }
    }
}

from sklearn.metrics import recall_score
from itertools import product
import signal

# Definir la excepción que se levantará si se excede el tiempo límite
class TimeoutException(Exception):
    pass

# Definir el manejador de señal para el tiempo límite
def timeout_handler(signum, frame):
    raise TimeoutException

# Asignar el manejador de señal a la señal de alarma
signal.signal(signal.SIGALRM, timeout_handler)

# Crear un diccionario para almacenar el mejor modelo y el mejor recall
best_model = None
best_recall = 0
best_params = None
best_model_name = None

# Iterar sobre cada modelo y sus hiperparámetros
for model_name, config in models_configs.items():
    model = config['model']
    param_grid = config['params']

    # Generar todas las combinaciones posibles de hiperparámetros
    param_combinations = list(product(*param_grid.values()))
    param_keys = list(param_grid.keys())

    for params in param_combinations:
        params_dict = dict(zip(param_keys, params))

        # Crear el modelo con los hiperparámetros actuales
        model.set_params(**params_dict)

        # Entrenar el modelo con los datos de entrenamiento
        try:
            # Configurar la alarma para 60 segundos
            signal.alarm(60)  # Tiempo límite de 60 segundos

            # Intentar entrenar el modelo
            model.fit(X_train, y_train)

            # Desactivar la alarma después de que se complete el ajuste
            signal.alarm(0)

            # Predecir con el modelo en los datos de prueba
            y_pred = model.predict(X_test)

            # Calcular el recall en los datos de prueba
            recall = recall_score(y_test, y_pred)

            # Verificar si esta combinación es la mejor hasta ahora
            if recall > best_recall:
                best_recall = recall
                best_model = model
                best_params = params_dict
                best_model_name = model_name

        except TimeoutException:
            print(f"Configuración tardó demasiado tiempo: {model_name} con parámetros {params_dict}. Saltando a la siguiente.")
            continue
        except Exception as e:
            # Imprimir el error si ocurre una excepción y continuar con la siguiente iteración
            # print(f"Error al ajustar el modelo {model_name} con los parámetros {params_dict}: {e}")
            continue

# Mostrar el mejor modelo, los mejores parámetros y el mejor recall
print(f"Mejor recall para {best_model_name}: {best_recall:.4f}")
print(f"Mejores parámetros: {best_params}")

"""# Optuna"""

pip install optuna

import optuna
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def objective(trial):

    try:

        # Seleccionar el modelo
        model_name = trial.suggest_categorical('model', [
            'LogisticRegression',
            'DecisionTreeClassifier',
            'RandomForestClassifier',
            'KNeighborsClassifier',
            'GaussianNB'
        ])

        if model_name == 'LogisticRegression':
          model = LogisticRegression(
              C=trial.suggest_loguniform('C', 1e-4, 1e2),
              solver=trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear']),
              max_iter=trial.suggest_int('max_iter', 50, 300),
              penalty=trial.suggest_categorical('penalty', ['l2', 'none']),
              multi_class=trial.suggest_categorical('multi_class', ['auto', 'ovr', 'multinomial'])
          )

        elif model_name == 'DecisionTreeClassifier':
            model = DecisionTreeClassifier(
                criterion=trial.suggest_categorical('criterion', ['gini', 'entropy']),
                max_depth=trial.suggest_int('max_depth', 1, 20),
                min_samples_split=trial.suggest_int('min_samples_split', 2, 20),
                min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 20),
                max_leaf_nodes=trial.suggest_int('max_leaf_nodes', 5, 30)
            )

        elif model_name == 'RandomForestClassifier':
            model = RandomForestClassifier(
                n_estimators=trial.suggest_int('n_estimators', 10, 100),
                max_depth=trial.suggest_int('max_depth', 2, 32),
                min_samples_split=trial.suggest_int('min_samples_split', 2, 16),
                bootstrap=trial.suggest_categorical('bootstrap', [True, False]),
                max_features=trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),
                oob_score=trial.suggest_categorical('oob_score', [True, False])
            )

        elif model_name == 'KNeighborsClassifier':
            model = KNeighborsClassifier(
                n_neighbors=trial.suggest_int('n_neighbors', 1, 20),
                weights=trial.suggest_categorical('weights', ['uniform', 'distance']),
                p=trial.suggest_int('p', 1, 2),
                algorithm=trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),
                leaf_size=trial.suggest_int('leaf_size', 20, 60)
            )

        elif model_name == 'GaussianNB':
            model = GaussianNB(var_smoothing=trial.suggest_loguniform('var_smoothing', 1e-9, 1e-3))

        # Entrenar el modelo
        model.fit(X_train, y_train)

        # Evaluar el modelo
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)

        return accuracy

    except Exception as e:
        # Imprimir el error y retornar una baja precisión en caso de fallo
        print(f"Error en el ensayo: {e}")
        return 0.0

study = optuna.create_study(direction='maximize')  # Maximizar la precisión
study.optimize(objective, n_trials=5000)  # Realizar 100 ensayos

# Mejor resultado
print(f"Best trial: {study.best_trial.value}")
print(f"Best params: {study.best_trial.params}")

print("Best model parameters:")
for param in study.best_trial.params:
    print(f"{param}: {study.best_trial.params[param]}")

best_params = study.best_trial.params
best_model_name = best_params.pop('model')

# Seleccionar el modelo final con los mejores hiperparámetros
if best_model_name == 'LogisticRegression':
    final_model = LogisticRegression(**best_params)
elif best_model_name == 'DecisionTreeClassifier':
    final_model = DecisionTreeClassifier(**best_params)
elif best_model_name == 'RandomForestClassifier':
    final_model = RandomForestClassifier(**best_params)
elif best_model_name == 'KNeighborsClassifier':
    final_model = KNeighborsClassifier(**best_params)
elif best_model_name == 'GaussianNB':
    final_model = GaussianNB()

# Entrenar el modelo final
final_model.fit(X_train, y_train)

# Evaluar el modelo
y_pred = final_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(accuracy)

result_df = pd.DataFrame({
    'PassengerId': df_test['ID'],  # 'ID' debe ser la columna del DataFrame df_test que contiene los IDs de los pasajeros
})

# y_pred = modelo.predict(X_test)

# Agregar la columna 'Survived' con las predicciones binarias
result_df['Survived'] = y_pred

# Mostrar el DataFrame resultante
result_df.to_csv('prediccionesFinal.csv', index=False)



# Crear el modelo con los parámetros especificados
modelo = DecisionTreeClassifier(
    criterion='entropy',
    max_depth=6,
    min_samples_split=17,
    min_samples_leaf=3,
    max_leaf_nodes=27,
    random_state=42  # Puedes cambiar o eliminar este parámetro si no deseas un resultado reproducible
)

# Supongamos que X_train y y_train son tus datos de entrada y salida de entrenamiento
# Entrenar el modelo
modelo.fit(X_train, y_train)

result_df = pd.DataFrame({
    'PassengerId': df_test['ID'],  # 'ID' debe ser la columna del DataFrame df_test que contiene los IDs de los pasajeros
})

y_pred = modelo.predict(X_test)

# Agregar la columna 'Survived' con las predicciones binarias
result_df['Survived'] = y_pred

# Mostrar el DataFrame resultante
result_df

import pandas as pd

# Supongamos que tu DataFrame se llama 'df'
# Guarda el DataFrame en un archivo CSV
result_df.to_csv('prediccionesFinal.csv', index=False)  # index=False evita que se guarden los índices del DataFrame





"""# **FNN**
Continuación...
"""

!pip install tensorflow

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import make_classification
from tensorflow.keras.layers import LSTM

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    monitor= 'val_loss',    # Revisamos la función loss de la validación
    patience= 8,            # Numero de épocas que tienen que pasar sin mejora
    restore_best_weights=True  # Guardamos los pesos de la mejor época
)

# Definir la red neuronal secuencial
model_FNN = Sequential([
    # Capa densa (completamente conectada) con 64 neuronas y función de activación ReLU
    # input_dim=X_train.shape[1] establece la dimensión de entrada de acuerdo a las características del conjunto de entrenamiento
    Dense(64, input_dim=X_train.shape[1], activation='relu'),
    # Segunda capa densa con 32 neuronas y función de activación ReLU
    Dense(32, activation='relu'),
    # Capa de salida con 1 neurona y función de activación sigmoide para la predicción binaria
    Dense(1, activation='sigmoid')
])

# Compilar el modelo
# optimizer='adam' especifica el optimizador Adam
# loss='binary_crossentropy' especifica la función de pérdida para clasificación binaria
# metrics=['accuracy'] especifica que se rastreará la métrica de precisión durante el entrenamiento y la evaluación
model_FNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['recall'])

# Entrenar el modelo
# epochs=100 especifica que el entrenamiento se realizará durante 100 épocas
# batch_size=32 especifica que el tamaño del lote será de 32 muestras
# validation_split=0.1 reserva el 10% de los datos de entrenamiento para validación
# verbose=1 habilita la salida detallada del proceso de entrenamiento
history = model_FNN.fit(X_train, y_train, epochs=1000, batch_size=128, validation_split=0.1, verbose=1, callbacks = [early_stopping])

# Evaluar el modelo en el conjunto de validación
# loss, accuracy devuelve la pérdida y precisión del modelo en el conjunto de validación
loss, accuracy = model_FNN.evaluate(X_test, y_test)

# Imprimir la pérdida y precisión del modelo en el conjunto de validación
print(f'Test Loss: {loss:.4f}')
print(f'Test Accuracy: {accuracy:.4f}')

# Generar las predicciones usando el modelo de red neuronal entrenado
y_pred_FNN = np.round(model_FNN.predict(X_test)).astype(int)
print('----------------Scores FNN----------------')
print('\nAccuracy -----', accuracy_score(y_test, y_pred_FNN))
print('\nRecall -------', recall_score(y_test, y_pred_FNN))
print('\nPrecision ----', precision_score(y_test, y_pred_FNN))
print('\nF1 Score -----', f1_score(y_test, y_pred_FNN))

# Crear un DataFrame para almacenar los resultados
result_df_FNN = pd.DataFrame({
    'PassengerId': df_test['ID'],  # 'ID' debe ser la columna del DataFrame df_test que contiene los IDs de los pasajeros
})

# Agregar la columna 'Survived' con las predicciones binarias
result_df_FNN['Survived'] = y_pred_FNN

# Mostrar el DataFrame resultante
result_df_FNN

"""# **XGBOOST & OPTUNA**

"""

!pip install optuna catboost

import xgboost as xgb
import optuna
from catboost import CatBoostClassifier, Pool

X_train_2, X_valid, y_train_2, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)

def objective(trial):
    params = {
        'objective': 'binary:logistic',
        'eval_metric': 'logloss',
        'verbosity': 0,
        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),
        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),
        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),
        'eta': trial.suggest_float('eta', 1e-8, 1.0, log=True),
        'max_depth': trial.suggest_int('max_depth', 1, 9),
        'min_child_weight': trial.suggest_float('min_child_weight', 1e-8, 1.0, log=True),
        'subsample': trial.suggest_float('subsample', 0.1, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),
    }
    dtrain = xgb.DMatrix(X_train_2, label=y_train_2)
    dvalid = xgb.DMatrix(X_valid, label=y_valid)
    model = xgb.train(params, dtrain, evals=[(dvalid, 'eval')], early_stopping_rounds=10, verbose_eval=False)

    # Make predictions
    preds = model.predict(dvalid)
    pred_labels = [1 if p > 0.5 else 0 for p in preds]

    # Evaluate the model
    accuracy = accuracy_score(y_valid, pred_labels)

    return 1 - accuracy

study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

print("Best trial:")
trial = study.best_trial
print("  Value: {}".format(trial.value))
print("  Params: ")
for key, value in trial.params.items():
    print("    {}: {}".format(key, value))

best_params = trial.params
model_xgb = xgb.XGBClassifier(**best_params)
model_xgb.fit(X_train, y_train)

y_pred_xgb = np.round(model_xgb.predict(X_test)).astype(int)
print('----------------Scores XGB----------------')
print('\nAccuracy -----', accuracy_score(y_test, y_pred_xgb))
print('\nRecall -------', recall_score(y_test, y_pred_xgb))
print('\nPrecision ----', precision_score(y_test, y_pred_xgb))
print('\nF1 Score -----', f1_score(y_test, y_pred_xgb))

