{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwmEcv0WvpHa"
      },
      "source": [
        "# **Importación de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x3RiQC_6lcIT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# URL del archivo CSV en GitHub\n",
        "train =  pd.read_csv('https://media.githubusercontent.com/media/Jacks3262/repo_HACKATHON_2024/main/Datasets/fraude.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb-JOmdt7xd0"
      },
      "source": [
        "La seleccion de los valores de test se utilizaron en base a los valores correctos obtenidos del repositorio de Github obtenidos a través de Kaggle: https://www.kaggle.com/datasets/wesleyhowe/titanic-labelled-test-set. Esto fue consultado con el profesor Ivan, debido a que se obtiene un 100% de accuracy al subirlo en Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ehh3hal__m_O"
      },
      "outputs": [],
      "source": [
        "df = train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK3yLrw_FNM4"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0b7foVuCaidj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e839829-22c8-42ee-916e-4348331ec701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: (243894, 12)\n",
            "Test set size: (104527, 12)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suponiendo que tienes un DataFrame llamado 'df' y quieres predecir una variable llamada 'target'\n",
        "X = df[['edad_cliente', 'monto_transaccion', 'mañana', 'tarde', 'noche', 'madrugada', 'presencial', 'nacional', 'internacional', 'sexo',\n",
        "        'fechas_decembrinas', 'categoria_peligrosa']] # Características (X)\n",
        "y = df['Fraude']  # Variable de respuesta (y)\n",
        "\n",
        "# Dividir el DataFrame en un 80% para entrenamiento y 20% para prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Ajustar el escalador solo con los datos de entrenamiento y transformar\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transformar el conjunto de prueba usando el mismo escalador\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Mostrar el tamaño de los conjuntos\n",
        "print(f\"Train set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "iIGcUu6aBYop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425fa560-9a99-43ea-e24b-740115bd72a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104527"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUtXmlEyWbTI"
      },
      "source": [
        "Calcula e imprime la exactitud, recall, f1-score, precisión y el área bajo la curva ROC (ROC AUC) para los datos de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "g7giANgzaiba"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
        "\n",
        "def print_scores(fitted_model):\n",
        "    res = {\n",
        "        \"Accuracy on train:\": accuracy_score(fitted_model.predict(X_train), y_train),\n",
        "        \"Recall on train:\": recall_score(fitted_model.predict(X_train), y_train),\n",
        "        \"Precision on train:\": precision_score(fitted_model.predict(X_train), y_train),\n",
        "        \"F1-Score on train:\": f1_score(fitted_model.predict(X_train), y_train),\n",
        "        \"ROC AUC on train:\": roc_auc_score(y_train, fitted_model.predict_proba(X_train)[:, 1]),\n",
        "\n",
        "        \"Accuracy on test:\": accuracy_score(fitted_model.predict(X_test), y_test),\n",
        "        \"Recall on test:\": recall_score(fitted_model.predict(X_test), y_test),\n",
        "        \"Precision on test:\": precision_score(fitted_model.predict(X_test), y_test),\n",
        "        \"F1-Score on test:\": f1_score(fitted_model.predict(X_test), y_test),\n",
        "        \"ROC AUC on test:\": roc_auc_score(y_test, fitted_model.predict_proba(X_test)[:, 1]),\n",
        "    }\n",
        "\n",
        "    # Imprimir solo las métricas de prueba (test) con un formato específico\n",
        "    for k, v in res.items():\n",
        "        #if 'on test' in k:  # Filtrar para incluir solo las claves que contienen 'on test'\n",
        "            print(k, round(v, 3))\n",
        "    print(\"-\" * 30)  # Línea separadora para claridad en la salida\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMZ72b3RJe2V"
      },
      "source": [
        "# **Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jy-T3qLUXCoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e97881c5-955e-4772-f89e-3ae7da41ed78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Logística\n",
            "Accuracy on train: 0.95\n",
            "Recall on train: 1.0\n",
            "Precision on train: 0.01\n",
            "F1-Score on train: 0.02\n",
            "ROC AUC on train: 0.95\n",
            "Accuracy on test: 0.952\n",
            "Recall on test: 1.0\n",
            "Precision on test: 0.009\n",
            "F1-Score on test: 0.018\n",
            "ROC AUC on test: 0.953\n",
            "------------------------------\n",
            "Accuracy on train: 0.967\n",
            "Recall on train: 0.731\n",
            "Precision on train: 0.547\n",
            "F1-Score on train: 0.625\n",
            "ROC AUC on train: 0.986\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.739\n",
            "Precision on test: 0.555\n",
            "F1-Score on test: 0.634\n",
            "ROC AUC on test: 0.987\n",
            "------------------------------\n",
            "Accuracy on train: 0.964\n",
            "Recall on train: 0.764\n",
            "Precision on train: 0.421\n",
            "F1-Score on train: 0.543\n",
            "ROC AUC on train: 0.986\n",
            "Accuracy on test: 0.966\n",
            "Recall on test: 0.778\n",
            "Precision on test: 0.43\n",
            "F1-Score on test: 0.554\n",
            "ROC AUC on test: 0.987\n",
            "------------------------------\n",
            "\n",
            "Árboles de decisión\n",
            "Accuracy on train: 0.998\n",
            "Recall on train: 0.986\n",
            "Precision on train: 0.978\n",
            "F1-Score on train: 0.982\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.681\n",
            "Precision on test: 0.677\n",
            "F1-Score on test: 0.679\n",
            "ROC AUC on test: 0.841\n",
            "------------------------------\n",
            "Accuracy on train: 0.989\n",
            "Recall on train: 0.903\n",
            "Precision on train: 0.877\n",
            "F1-Score on train: 0.89\n",
            "ROC AUC on train: 0.998\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.69\n",
            "Precision on test: 0.667\n",
            "F1-Score on test: 0.678\n",
            "ROC AUC on test: 0.911\n",
            "------------------------------\n",
            "Accuracy on train: 0.993\n",
            "Recall on train: 0.96\n",
            "Precision on train: 0.904\n",
            "F1-Score on train: 0.931\n",
            "ROC AUC on train: 0.999\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.689\n",
            "Precision on test: 0.649\n",
            "F1-Score on test: 0.669\n",
            "ROC AUC on test: 0.878\n",
            "------------------------------\n",
            "\n",
            "Random Forest\n",
            "Accuracy on train: 0.999\n",
            "Recall on train: 0.989\n",
            "Precision on train: 0.991\n",
            "F1-Score on train: 0.99\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.97\n",
            "Recall on test: 0.691\n",
            "Precision on test: 0.695\n",
            "F1-Score on test: 0.693\n",
            "ROC AUC on test: 0.986\n",
            "------------------------------\n",
            "Accuracy on train: 0.999\n",
            "Recall on train: 0.989\n",
            "Precision on train: 0.993\n",
            "F1-Score on train: 0.991\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.97\n",
            "Recall on test: 0.691\n",
            "Precision on test: 0.7\n",
            "F1-Score on test: 0.695\n",
            "ROC AUC on test: 0.988\n",
            "------------------------------\n",
            "Accuracy on train: 0.999\n",
            "Recall on train: 0.99\n",
            "Precision on train: 0.992\n",
            "F1-Score on train: 0.991\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.97\n",
            "Recall on test: 0.691\n",
            "Precision on test: 0.702\n",
            "F1-Score on test: 0.696\n",
            "ROC AUC on test: 0.989\n",
            "------------------------------\n",
            "Accuracy on train: 0.996\n",
            "Recall on train: 0.954\n",
            "Precision on train: 0.965\n",
            "F1-Score on train: 0.959\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.971\n",
            "Recall on test: 0.697\n",
            "Precision on test: 0.721\n",
            "F1-Score on test: 0.709\n",
            "ROC AUC on test: 0.989\n",
            "------------------------------\n",
            "Accuracy on train: 0.991\n",
            "Recall on train: 0.9\n",
            "Precision on train: 0.923\n",
            "F1-Score on train: 0.911\n",
            "ROC AUC on train: 0.999\n",
            "Accuracy on test: 0.972\n",
            "Recall on test: 0.703\n",
            "Precision on test: 0.727\n",
            "F1-Score on test: 0.715\n",
            "ROC AUC on test: 0.99\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Regresión Logística\n",
        "print('Regresión Logística')\n",
        "\n",
        "# Modelo 1: Regresión Logística con C=0.01, solver='liblinear', max_iter=1000\n",
        "model_1 = LogisticRegression(C=0.01, solver='liblinear', max_iter=1000)\n",
        "model_1.fit(X_train, y_train)\n",
        "print_scores(model_1)\n",
        "\n",
        "\n",
        "# Modelo 2: Regresión Logística con C=1, solver='sag', max_iter=2000\n",
        "#model_2 = LogisticRegression(C=1, solver='sag', max_iter=2000)\n",
        "#model_2.fit(X_train, y_train)\n",
        "#print_scores(model_2)\n",
        "\n",
        "# Modelo 3: Regresión Logística con C=10, solver='newton-cg', max_iter=3000\n",
        "model_3 = LogisticRegression(C=10, solver='newton-cg', max_iter=3000)\n",
        "model_3.fit(X_train, y_train)\n",
        "print_scores(model_3)\n",
        "\n",
        "# Modelo 4: Regresión Logística con C=0.05, solver='saga', max_iter=5000, penalty='l2'\n",
        "# model_4 = LogisticRegression(C=0.05, solver='saga', max_iter=5000, penalty='l2')\n",
        "# model_4.fit(X_train, y_train)\n",
        "# print_scores(model_4)\n",
        "\n",
        "# Modelo 5: Regresión Logística con C=0.5, solver='lbfgs', max_iter=1000, penalty='l2'\n",
        "model_5 = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, penalty='l2')\n",
        "model_5.fit(X_train, y_train)\n",
        "print_scores(model_5)\n",
        "\n",
        "print('')\n",
        "print('Árboles de decisión')\n",
        "\n",
        "# Árbol de decisión 1: max_depth=30, min_samples_split=2, criterion='gini'\n",
        "tree_model_1 = DecisionTreeClassifier(max_depth=30, min_samples_split=2, criterion='gini')\n",
        "tree_model_1.fit(X_train, y_train)\n",
        "print_scores(tree_model_1)\n",
        "\n",
        "# Árbol de decisión 2: max_depth=100, min_samples_split=10, criterion='entropy'\n",
        "tree_model_2 = DecisionTreeClassifier(max_depth=100, min_samples_split=10, criterion='entropy')\n",
        "tree_model_2.fit(X_train, y_train)\n",
        "print_scores(tree_model_2)\n",
        "\n",
        "# Árbol de decisión 3: max_depth=150, min_samples_split=5, criterion='gini'\n",
        "tree_model_3 = DecisionTreeClassifier(max_depth=150, min_samples_split=5, criterion='gini')\n",
        "tree_model_3.fit(X_train, y_train)\n",
        "print_scores(tree_model_3)\n",
        "\n",
        "print('')\n",
        "print('Random Forest')\n",
        "\n",
        "# Random Forest 1: n_estimators=50, max_features='sqrt', max_depth=50\n",
        "rf_model_1 = RandomForestClassifier(n_estimators=50, max_features='sqrt', max_depth=50)\n",
        "rf_model_1.fit(X_train, y_train)\n",
        "print_scores(rf_model_1)\n",
        "\n",
        "# Random Forest 2: n_estimators=100, max_features='log2', max_depth=100\n",
        "rf_model_2 = RandomForestClassifier(n_estimators=100, max_features='log2', max_depth=100)\n",
        "rf_model_2.fit(X_train, y_train)\n",
        "print_scores(rf_model_2)\n",
        "\n",
        "# Random Forest 3: n_estimators=200, max_features='sqrt', max_depth=200\n",
        "rf_model_3 = RandomForestClassifier(n_estimators=200, max_features='sqrt', max_depth=200)\n",
        "rf_model_3.fit(X_train, y_train)\n",
        "print_scores(rf_model_3)\n",
        "\n",
        "# Random Forest 4: n_estimators=150, max_features='sqrt', max_depth=250, min_samples_split=4\n",
        "rf_model_4 = RandomForestClassifier(n_estimators=150, max_features='sqrt', max_depth=250, min_samples_split=4)\n",
        "rf_model_4.fit(X_train, y_train)\n",
        "print_scores(rf_model_4)\n",
        "\n",
        "# Random Forest 5: n_estimators=300, max_features='log2', max_depth=300, min_samples_leaf=2\n",
        "rf_model_5 = RandomForestClassifier(n_estimators=300, max_features='log2', max_depth=300, min_samples_leaf=2)\n",
        "rf_model_5.fit(X_train, y_train)\n",
        "print_scores(rf_model_5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Mejor Modelo Convencional**"
      ],
      "metadata": {
        "id": "1wQp5ZYaYXDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, penalty='l2')\n",
        "model_5.fit(X_train, y_train)\n",
        "# print_scores(model_5)\n",
        "\n",
        "# Pedir al usuario que ingrese los valores de cada característica\n",
        "nuevo_registro = {\n",
        "    'edad_cliente': int(input('Enter the client\\'s age: ')),\n",
        "    'monto_transaccion': float(input('Enter the transaction amount: ')),\n",
        "    'mañana': int(input('Transaction in the morning? (1 for yes, 0 for no): ')),\n",
        "    'tarde': int(input('Transaction in the afternoon? (1 for yes, 0 for no): ')),\n",
        "    'noche': int(input('Transaction at night? (1 for yes, 0 for no): ')),\n",
        "    'madrugada': int(input('Transaction at dawn? (1 for yes, 0 for no): ')),\n",
        "    'presencial': int(input('In-person transaction? (1 for yes, 0 for no): ')),\n",
        "    'nacional': int(input('National transaction? (1 for yes, 0 for no): ')),\n",
        "    'internacional': int(input('International transaction? (1 for yes, 0 for no): ')),\n",
        "    'sexo': int(input('Client\\'s gender (1 for female, 0 for male): ')),\n",
        "    'fechas_decembrinas': int(input('Transaction during December holidays? (1 for yes, 0 for no): ')),\n",
        "    'categoria_peligrosa': int(input('Dangerous category? (1 for yes, 0 for no): '))\n",
        "}\n",
        "\n",
        "# Convertir el registro a DataFrame y asegurarse de que siga el orden de las columnas de entrenamiento\n",
        "X_nuevo = pd.DataFrame([nuevo_registro])\n",
        "\n",
        "# Escalar los datos si fue parte del preprocesamiento\n",
        "X_nuevo_scaled = scaler.transform(X_nuevo)\n",
        "\n",
        "# Realizar la predicción\n",
        "prediccion = model_5.predict(X_nuevo_scaled)\n",
        "\n",
        "# Mostrar la predicción\n",
        "if prediccion[0] == 0:\n",
        "    print('No Fraud')\n",
        "else:\n",
        "    print('Fraud')\n",
        "\n",
        "print('----------------------------------')\n",
        "\n",
        "# Pedir al usuario que ingrese los valores de cada característica\n",
        "nuevo_registro = {\n",
        "    'edad_cliente': int(input('Enter the client\\'s age: ')),\n",
        "    'monto_transaccion': float(input('Enter the transaction amount: ')),\n",
        "    'mañana': int(input('Transaction in the morning? (1 for yes, 0 for no): ')),\n",
        "    'tarde': int(input('Transaction in the afternoon? (1 for yes, 0 for no): ')),\n",
        "    'noche': int(input('Transaction at night? (1 for yes, 0 for no): ')),\n",
        "    'madrugada': int(input('Transaction at dawn? (1 for yes, 0 for no): ')),\n",
        "    'presencial': int(input('In-person transaction? (1 for yes, 0 for no): ')),\n",
        "    'nacional': int(input('National transaction? (1 for yes, 0 for no): ')),\n",
        "    'internacional': int(input('International transaction? (1 for yes, 0 for no): ')),\n",
        "    'sexo': int(input('Client\\'s gender (1 for female, 0 for male): ')),\n",
        "    'fechas_decembrinas': int(input('Transaction during December holidays? (1 for yes, 0 for no): ')),\n",
        "    'categoria_peligrosa': int(input('Dangerous category? (1 for yes, 0 for no): '))\n",
        "}\n",
        "\n",
        "# Convertir el registro a DataFrame y asegurarse de que siga el orden de las columnas de entrenamiento\n",
        "X_nuevo = pd.DataFrame([nuevo_registro])\n",
        "\n",
        "# Escalar los datos si fue parte del preprocesamiento\n",
        "X_nuevo_scaled = scaler.transform(X_nuevo)\n",
        "\n",
        "# Realizar la predicción\n",
        "prediccion = model_5.predict(X_nuevo_scaled)\n",
        "\n",
        "# Mostrar la predicción\n",
        "if prediccion[0] == 0:\n",
        "    print('No Fraud')\n",
        "else:\n",
        "    print('Fraud')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9fyoR9gYGoh",
        "outputId": "a929aac6-248f-4fb8-9791-9de4f91d7738"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the client's age: 22\n",
            "Enter the transaction amount: 200\n",
            "Transaction in the morning? (1 for yes, 0 for no): 1\n",
            "Transaction in the afternoon? (1 for yes, 0 for no): 0\n",
            "Transaction at night? (1 for yes, 0 for no): 0\n",
            "Transaction at dawn? (1 for yes, 0 for no): 0\n",
            "In-person transaction? (1 for yes, 0 for no): 0\n",
            "National transaction? (1 for yes, 0 for no): 1\n",
            "International transaction? (1 for yes, 0 for no): 0\n",
            "Client's gender (1 for female, 0 for male): 1\n",
            "Transaction during December holidays? (1 for yes, 0 for no): 1\n",
            "Dangerous category? (1 for yes, 0 for no): 0\n",
            "No Fraud\n",
            "----------------------------------\n",
            "Enter the client's age: 22\n",
            "Enter the transaction amount: 2000\n",
            "Transaction in the morning? (1 for yes, 0 for no): 0\n",
            "Transaction in the afternoon? (1 for yes, 0 for no): 0\n",
            "Transaction at night? (1 for yes, 0 for no): 1\n",
            "Transaction at dawn? (1 for yes, 0 for no): 0\n",
            "In-person transaction? (1 for yes, 0 for no): 0\n",
            "National transaction? (1 for yes, 0 for no): 0\n",
            "International transaction? (1 for yes, 0 for no): 1\n",
            "Client's gender (1 for female, 0 for male): 1\n",
            "Transaction during December holidays? (1 for yes, 0 for no): 1\n",
            "Dangerous category? (1 for yes, 0 for no): 1\n",
            "Fraud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iO6EoLa_YGli"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}